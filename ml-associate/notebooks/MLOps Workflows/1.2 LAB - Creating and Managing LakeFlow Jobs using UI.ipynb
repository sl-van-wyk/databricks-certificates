{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de5a8b36-3ed7-478b-834c-9a31e8f23224",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "918d9c15-e598-4966-81d9-fe62677c3668",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# LAB - Creating and Managing LakeFlow Jobs using UI\n",
    "\n",
    "In this lab, you will learn how to set up a LakeFlow Jobs to deploy a machine learning model with manual triggers and email notifications using the Databricks UI. This will involve creating tasks in the LakeFlow Jobs, configuring job dependencies, and enabling email notifications.\n",
    "\n",
    "**Lab Outline:**\n",
    "\n",
    "_In this lab, you will complete the following tasks:_\n",
    "\n",
    "- Create and configure a LakeFlow Jobs with multiple tasks using the UI.\n",
    "- Enable email notifications for job status updates.\n",
    "- Manually trigger the deployment workflow.\n",
    "- Monitor the job run to ensure successful execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11df0eb0-ebc5-42d8-bb80-a3b95c589603",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "1. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "   - In the drop-down, select **More**.\n",
    "   - In the **Attach to an existing compute resource** pop-up, select the first drop-down. You will see a unique cluster name in that drop-down. Please select that cluster.\n",
    "  \n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "1. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "1. Wait a few minutes for the cluster to start.\n",
    "1. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "caadcff8-5904-4a73-8e24-371d8608959e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "- To run this notebook, you need to use one of the following Databricks runtime(s): `16.3.x-cpu-ml-scala2.12`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c46649ce-9de2-4734-a828-7e9902b6e667",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 1: Create a Databricks Job\n",
    "\n",
    "1. **Navigate to Jobs & Pipelines**:\n",
    "   - In your Databricks workspace, click on the **Jobs & Pipelines** icon in the left sidebar.\n",
    "   \n",
    "2. **Create a New Job**:\n",
    "   - Click on **Create** in the upper-right corner of the Jobs & Pipelines page and Select **Job**.\n",
    "   - Name the job, for example, \"ML Model Training Workflow\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d88cf95d-1f28-45f1-b967-461f945e6761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 2: Add Tasks to the Job:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91930a79-1441-44a5-9be3-a3c6dcd21fef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> - ### Task 1: Data Cleaning and Feature Engineering\n",
    "> \n",
    "> 1. **Add First Task**:\n",
    ">    - Name the task: `Data_Cleaning_and_Feature_Engineering`.\n",
    ">    - Set **Type** to `Notebook`.\n",
    ">    - Set **Source** to `Workspace`.\n",
    ">    - Set **Path** to the notebook path: `$/1.2 Lab Pipeline - Data Cleaning and Model Training/1.2a LAB - Data Cleaning and Feature Engineering`.\n",
    ">    - Choose an appropriate cluster for this task.\n",
    ">    - Click **Create Task**.\n",
    "> \n",
    "<!-- > ![Task 1 Configuration](https://s3.us-west-2.amazonaws.com/files.training.databricks.com/images/Data_Cleaning_and_Feature_Engineering_Task%2B1.png) -->\n",
    "![Data_Cleaning_and_Feature_Engineering_Task](../Includes/images/Data_Cleaning_and_Feature_Engineering_Task.png)\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c932f9c3-85f1-404a-a298-4005e04faa8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> - ### Task 2: Model Training\n",
    "> \n",
    "> 2. **Add Second Task**:\n",
    ">    - Click on **Add Task --> Notebook**.\n",
    ">    - Name the task: `Model_Training`.\n",
    ">    - Set **Type** to `Notebook`.\n",
    ">    - Set **Source** to `Workspace`.\n",
    ">    - Set **Path** to the notebook path: `$/1.2 Lab Pipeline - Data Cleaning and Model Training/1.2b LAB - Model Training and Tracking with MLFlow`.\n",
    ">    - Choose the same cluster as the first task.\n",
    ">    - Set **Depends on** to `Data_Cleaning_and_Feature_Engineering`.\n",
    ">    - Click **Create Task**.\n",
    "> \n",
    "<!-- > ![Task 2 Configuration](https://s3.us-west-2.amazonaws.com/files.training.databricks.com/images/Model_Training_Task_2%2B.png) -->\n",
    "![Model_Training_Task](../Includes/images/Model_Training_Task.png)\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52af148d-23a9-4f14-9bad-997e1d394639",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 3: Enable Email Notifications\n",
    "\n",
    "1. **Enable Notifications**:\n",
    "   - For task 2, click on **Edit Notification** under **Job Notifications**\n",
    "   - Add your email to receive notifications on job status updates.\n",
    "\n",
    "<!-- ![Email Notification Configuration](https://s3.us-west-2.amazonaws.com/files.training.databricks.com/images/Task+Notification.png) -->\n",
    "![Task+Notification](../Includes/images/Task+Notification.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0017a371-f32e-4a05-b796-1019abec57c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 4: Manually Trigger the Job Run\n",
    "\n",
    "1. **Run the Job**:\n",
    "   - Click on **Run Now** in the top right corner to manually trigger the job.\n",
    "\n",
    "<!-- ![Run Job](https://s3.us-west-2.amazonaws.com/files.training.databricks.com/images/Manually_trigger.png) -->\n",
    "![Manually_trigger](../Includes/images/Manually_trigger.png)\n",
    "\n",
    "**Optional:** You can also set a scheduled trigger from the Schedules & Triggers option as shown below:\n",
    "\n",
    "<!-- ![Scheduled Trigger](https://s3.us-west-2.amazonaws.com/files.training.databricks.com/images/Schedules+%26+Triggers.png) -->\n",
    "![Schedules+Triggers.png](../Includes/images/Schedules+Triggers.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "649fa491-75c7-4905-8fcb-8c6e8e1cdc88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 5: Monitor the Job Run\n",
    "\n",
    "1. **Navigate to the Runs Tab**:\n",
    "   - Go to the **Runs** tab to view current and past job executions.\n",
    "   \n",
    "2. **View Running Jobs**:\n",
    "   - Identify the job with a **Running** status.\n",
    "   - Click on the **Start Time** of the run to access detailed information.\n",
    "   \n",
    "3. **Observe Task Execution**:\n",
    "   - Select the **Task** square to observe the execution of individual cells and their outputs.\n",
    "   - Continue to explore until the run is fully completed. *It should take about 9-10 minutes*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0dcaf5c3-e696-48ae-8e44-bd4a8cf662ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lab, you have learned how to create and configure a Lakeflow job with multiple tasks using the Databricks UI. You also enabled email notifications for job status updates and manually triggered the deployment workflow. By monitoring the job run, you ensured successful execution of the tasks. This process helps in automating machine learning workflows, ensuring that data processing and model training are executed seamlessly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39a173cb-8676-4af6-8900-8a00bf16750e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "&copy; 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"blank\">Apache Software Foundation</a>.<br/>\n",
    "<br/><a href=\"https://databricks.com/privacy-policy\" target=\"blank\">Privacy Policy</a> | \n",
    "<a href=\"https://databricks.com/terms-of-use\" target=\"blank\">Terms of Use</a> | \n",
    "<a href=\"https://help.databricks.com/\" target=\"blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1.2 LAB - Creating and Managing LakeFlow Jobs using UI",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}